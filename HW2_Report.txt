For this HW2, I ran all my program on the courant server, the CPU has 4 cores and the detail
of it is the following,
processor       : 0
vendor_id       : AuthenticAMD
cpu family      : 23
model           : 1
model name      : AMD EPYC Processor (with IBPB)
stepping        : 2
microcode       : 0x1000065
cpu MHz         : 2894.562
cache size      : 512 KB
physical id     : 0
siblings        : 1
core id         : 0
cpu cores       : 1
apicid          : 0
initial apicid  : 0
fpu             : yes
fpu_exception   : yes
cpuid level     : 13
wp              : yes
flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm art rep_good nopl extd_apicid eagerfpu pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm cmp_legacy cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw topoext ssbd rsb_ctxsw ibpb vmmcall fsgsbase tsc_adjust bmi1 avx2 smep bmi2 rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 retpoline_amd virt_ssbd arat umip
bogomips        : 5789.12
TLB size        : 1024 4K pages
clflush size    : 64
cache_alignment : 64
address sizes   : 48 bits physical, 48 bits virtual
power management:

2.
First, I use BLOCK_SIZE = 16, the following is the output,
 Dimension       Time    Gflop/s       GB/s        Error
        16   0.529360   3.778150   3.778150 0.000000e+00
        64   0.581388   3.440317   1.505139 0.000000e+00
       112   0.391803   5.106182   1.823637 0.000000e+00
       160   0.391446   5.127251   1.666357 0.000000e+00
       208   0.459384   4.387950   1.350139 0.000000e+00
       256   0.421536   4.776021   1.417881 0.000000e+00
       304   0.400443   5.051405   1.462249 0.000000e+00
       352   0.411176   4.879309   1.386167 0.000000e+00
       400   0.404793   5.059374   1.416625 0.000000e+00
       448   0.429446   5.025002   1.390849 0.000000e+00
       496   0.433098   5.071446   1.390558 0.000000e+00
       544   0.446279   5.050310   1.373981 0.000000e+00
       592   0.409647   5.064719   1.368843 0.000000e+00
       640   0.414797   5.055857   1.358762 0.000000e+00
       688   0.515621   5.052714   1.351307 0.000000e+00
       736   0.473958   5.047139   1.344075 0.000000e+00
       784   0.575306   5.025748   1.333362 0.000000e+00
       832   0.455152   5.061436   1.338360 0.000000e+00
       880   0.536370   5.082106   1.339828 0.000000e+00
       928   0.632167   5.056757   1.329578 0.000000e+00
       976   0.741321   5.016530   1.315811 0.000000e+00
      1024   0.477758   4.494923   1.176406 0.000000e+00
      1072   0.488015   5.048716   1.318694 0.000000e+00
      1120   0.559756   5.019787   1.308730 0.000000e+00
      1168   0.640415   4.976193   1.295173 0.000000e+00
      1216   0.725946   4.953660   1.287300 0.000000e+00
      1264   0.893215   4.521840   1.173389 0.000000e+00
      1312   0.916494   4.928354   1.277165 0.000000e+00
      1360   1.025229   4.907112   1.270076 0.000000e+00
      1408   1.178902   4.735437   1.224218 0.000000e+00
      1456   1.317490   4.685617   1.210022 0.000000e+00
      1504   1.495793   4.548853   1.173507 0.000000e+00
      1552   1.739561   4.297990   1.107729 0.000000e+00
      1600   1.731603   4.730875   1.218200 0.000000e+00
      1648   1.869352   4.788622   1.232024 0.000000e+00
      1696   2.034446   4.795803   1.232883 0.000000e+00
      1744   2.413365   4.395885   1.129218 0.000000e+00
      1792   2.613028   4.404535   1.130628 0.000000e+00
      1840   2.603078   4.786260   1.227780 0.000000e+00
      1888   2.820954   4.771336   1.223160 0.000000e+00
      1936   3.040070   4.773781   1.223035 0.000000e+00
      1984   3.276914   4.766394   1.220428 0.000000e+00
In this case, the theoretical peak FLOP-rate is equal to the BLOCK_SIZE = 16, during the output
we can observe that the peak FLOP-rate we has achieved is aroudn 5, so we has achieved
around 30% of our theoretical peak. Let's play with the BLOCK_SIZE, let decrease the BLOCK_SIZE
to 4,
BLOCK_SIZE = 4
We can get the following output,
 Dimension       Time    Gflop/s       GB/s        Error
         4   0.406097   4.924927  19.699709 0.000000e+00
        52   0.407490   4.908110   6.040751 0.000000e+00
       100   0.407655   4.911013   5.500335 0.000000e+00
       148   0.408482   4.904573   5.302241 0.000000e+00
       196   0.408630   4.901397   5.201483 0.000000e+00
       244   0.409912   4.890554   5.131073 0.000000e+00
       292   0.417715   4.887456   5.088310 0.000000e+00
       340   0.419789   4.868659   5.040494 0.000000e+00
       388   0.432576   4.861106   5.011450 0.000000e+00
       436   0.440221   4.895105   5.029833 0.000000e+00
       484   0.417962   4.882834   5.003896 0.000000e+00
       532   0.434987   4.846031   4.955340 0.000000e+00
       580   0.482124   4.856308   4.956784 0.000000e+00
       628   0.509963   4.856693   4.949496 0.000000e+00
       676   0.510142   4.844390   4.930385 0.000000e+00
       724   0.468853   4.856572   4.937067 0.000000e+00
       772   0.568481   4.856095   4.931578 0.000000e+00
       820   0.452847   4.870234   4.941505 0.000000e+00
       868   0.538195   4.860484   4.927680 0.000000e+00
       916   0.633243   4.854856   4.918457 0.000000e+00
       964   0.737782   4.856941   4.917401 0.000000e+00
      1012   0.424756   4.880133   4.938000 0.000000e+00
      1060   0.487549   4.885726   4.941036 0.000000e+00
      1108   0.558907   4.867539   4.920256 0.000000e+00
      1156   0.643454   4.801604   4.851447 0.000000e+00
      1204   0.729592   4.784423   4.832108 0.000000e+00
      1252   0.822098   4.774406   4.820167 0.000000e+00
      1300   0.929174   4.728934   4.772585 0.000000e+00
      1348   1.036530   4.726260   4.768334 0.000000e+00
      1396   1.155724   4.707954   4.748423 0.000000e+00
      1444   1.291856   4.661411   4.700149 0.000000e+00
      1492   1.422564   4.669437   4.706993 0.000000e+00
      1540   1.569598   4.653757   4.690020 0.000000e+00
      1588   1.743316   4.594152   4.628868 0.000000e+00
      1636   1.898268   4.613413   4.647252 0.000000e+00
      1684   2.029049   4.707212   4.740755 0.000000e+00
      1732   2.259083   4.599826   4.631696 0.000000e+00
      1780   2.451603   4.600869   4.631886 0.000000e+00
      1828   2.670441   4.574836   4.604868 0.000000e+00
      1876   2.899495   4.554138   4.583269 0.000000e+00
      1924   3.041503   4.683353   4.712563 0.000000e+00
      1972   3.309625   4.634170   4.662370 0.000000e+00
We can see that the FLOP-rate is decreasing, around 1, given that we are using BLOCK_SIZE=4,
so the theoretical peak FLOP-rate is 4, we have achieved around 25%, which drops from the case
BLOCK_SIZE =16. Then, we change the 
BLOCK_SIZE = 32
We can get the following output,
 Dimension       Time    Gflop/s       GB/s        Error
        32   0.391005   5.115097   2.557548 0.000000e+00
        64   0.392269   5.098951   1.593422 0.000000e+00
        96   0.375486   5.329816   1.332454 0.000000e+00
       128   0.370774   5.395965   1.180367 0.000000e+00
       160   0.391793   5.122702   1.024540 0.000000e+00
       192   0.392412   5.122475   0.960464 0.000000e+00
       224   0.374687   5.339440   0.953471 0.000000e+00
       256   0.394018   5.109578   0.878209 0.000000e+00
       288   0.387124   5.183303   0.863884 0.000000e+00
       320   0.406257   5.000814   0.812632 0.000000e+00
       352   0.383846   5.226712   0.831522 0.000000e+00
       384   0.403412   5.052979   0.789528 0.000000e+00
       416   0.386067   5.221257   0.803270 0.000000e+00
       448   0.407557   5.294888   0.803688 0.000000e+00
       480   0.423754   5.219638   0.782946 0.000000e+00
       512   0.420058   5.112346   0.758864 0.000000e+00
       544   0.444006   5.076167   0.746495 0.000000e+00
       576   0.447208   5.127895   0.747818 0.000000e+00
       608   0.419631   5.356030   0.775215 0.000000e+00
       640   0.393648   5.327482   0.765825 0.000000e+00
       672   0.475916   5.101144   0.728735 0.000000e+00
       704   0.415779   5.035078   0.715210 0.000000e+00
       736   0.466441   5.128471   0.724675 0.000000e+00
       768   0.532757   5.101591   0.717411 0.000000e+00
       800   0.394932   5.185705   0.725999 0.000000e+00
       832   0.436414   5.278748   0.735979 0.000000e+00
       864   0.488964   5.276234   0.732810 0.000000e+00
       896   0.564418   5.097803   0.705500 0.000000e+00
       928   0.596862   5.355866   0.738740 0.000000e+00
       960   0.694499   5.095679   0.700656 0.000000e+00
       992   0.747526   5.223586   0.716137 0.000000e+00
      1024   0.403252   5.325417   0.728084 0.000000e+00
      1056   0.440028   5.352308   0.729860 0.000000e+00
      1088   0.491007   5.246012   0.713612 0.000000e+00
      1120   0.558264   5.033204   0.683078 0.000000e+00
      1152   0.612862   4.989126   0.675611 0.000000e+00
      1184   0.669470   4.958543   0.670073 0.000000e+00
      1216   0.713286   5.041584   0.679950 0.000000e+00
      1248   0.792878   4.903059   0.660027 0.000000e+00
      1280   0.797669   5.258200   0.706571 0.000000e+00
      1312   0.916913   4.926104   0.660819 0.000000e+00
      1344   1.005521   4.828772   0.646711 0.000000e+00
      1376   1.100106   4.736428   0.633360 0.000000e+00
      1408   1.095233   5.097196   0.680591 0.000000e+00
      1440   1.192176   5.009301   0.667907 0.000000e+00
      1472   1.311463   4.864042   0.647658 0.000000e+00
      1504   1.394111   4.880634   0.649020 0.000000e+00
      1536   1.447163   5.008251   0.665158 0.000000e+00
      1568   1.653590   4.662732   0.618526 0.000000e+00
      1600   1.782489   4.595822   0.608946 0.000000e+00
      1632   1.886860   4.607346   0.609796 0.000000e+00
      1664   1.764644   5.221951   0.690402 0.000000e+00
      1696   2.024258   4.819941   0.636596 0.000000e+00
      1728   2.342360   4.405625   0.581298 0.000000e+00
      1760   2.261859   4.820616   0.635445 0.000000e+00
      1792   2.328544   4.942647   0.650929 0.000000e+00
      1824   2.615748   4.639900   0.610513 0.000000e+00
      1856   2.772406   4.612190   0.606344 0.000000e+00
      1888   2.851928   4.719515   0.619936 0.000000e+00
      1920   2.743585   5.159590   0.677196 0.000000e+00
      1952   3.135635   4.743992   0.622163 0.000000e+00
      1984   3.316561   4.709415   0.617161 0.000000e+00
We can see that this time the max FLOP-rate is around 8, which is still 25% of the peak 
FLOP-rate = 32 = BLOCK-size, comparing the the case when BLOCK-SIZE = 16. Then, let
BLOCK_SIZE = 64,
 Dimension       Time    Gflop/s       GB/s        Error
        64   0.216018   9.259236   2.314809 0.000000e+00
       128   0.221865   9.017568   1.408995 0.000000e+00
       192   0.219265   9.167532   1.145941 0.000000e+00
       256   0.225346   8.934121   0.977170 0.000000e+00
       320   0.223731   9.080639   0.908064 0.000000e+00
       384   0.230564   8.841084   0.828852 0.000000e+00
       448   0.238934   9.031649   0.806397 0.000000e+00
       512   0.269437   7.970260   0.684944 0.000000e+00
       576   0.289457   7.922535   0.660211 0.000000e+00
       640   0.259794   8.072367   0.655880 0.000000e+00
       704   0.255530   8.192691   0.651691 0.000000e+00
       768   0.333194   8.157134   0.637276 0.000000e+00
       832   0.279995   8.227727   0.632902 0.000000e+00
       896   0.355052   8.103859   0.615025 0.000000e+00
       960   0.437625   8.086696   0.606502 0.000000e+00
      1024   0.275854   7.784854   0.577782 0.000000e+00
      1088   0.318677   8.082869   0.594329 0.000000e+00
      1152   0.379688   8.053059   0.587202 0.000000e+00
      1216   0.450294   7.986095   0.577941 0.000000e+00
      1280   0.524046   8.003699   0.575266 0.000000e+00
      1344   0.629884   7.708449   0.550603 0.000000e+00
      1408   0.738944   7.554857   0.536567 0.000000e+00
      1472   0.825463   7.727803   0.545986 0.000000e+00
      1536   0.937376   7.731965   0.543654 0.000000e+00
      1600   1.055959   7.757881   0.543052 0.000000e+00
      1664   1.217055   7.571464   0.527818 0.000000e+00
      1728   1.338453   7.710064   0.535421 0.000000e+00
      1792   1.573607   7.313877   0.506094 0.000000e+00
      1856   1.693175   7.552001   0.520828 0.000000e+00
      1920   1.845787   7.669236   0.527260 0.000000e+00
      1984   2.010629   7.768249   0.532501 0.000000e+00
The max FLOP-rate would be 16, still around 25% of the peak FLOP-rate, if we continue to
increase the BLOCK_SIZE, the block matrix may no longer can be store into cache anymore, 
so we stop at here. To conclude, when BLOCK_SIZE is 16, we achieve the largest percentage 
with respect to the theoretical FLOP-rate, when BLOCK_SIZE is 64, we get the largest FLOP-rate.
Compare the time also, 64 would be the optimal BLOCK_SIZE.
If we change the order of the multiplication, the original order we are using is j,p,i. If we change to
j,i,p, we can get the following output when BLOCK_SIZE is 16,
 Dimension       Time    Gflop/s       GB/s        Error
        16   0.666727   2.999734   2.999734 0.000000e+00
        64   0.670555   2.982840   1.304992 0.000000e+00
       112   0.670223   2.985002   1.066072 0.000000e+00
       160   0.673551   2.979790   0.968432 0.000000e+00
       208   0.674852   2.986962   0.919065 0.000000e+00
       256   0.770906   2.611559   0.775307 0.000000e+00
       304   0.678901   2.979524   0.862494 0.000000e+00
       352   0.673726   2.977848   0.845979 0.000000e+00
       400   0.690196   2.967271   0.830836 0.000000e+00
       448   0.732462   2.946185   0.815462 0.000000e+00
       496   0.751889   2.921216   0.800979 0.000000e+00
       544   0.767066   2.938271   0.799383 0.000000e+00
       592   0.707385   2.932982   0.792698 0.000000e+00
       640   0.716393   2.927378   0.786733 0.000000e+00
       688   0.885210   2.943127   0.787115 0.000000e+00
       736   0.816775   2.928751   0.779939 0.000000e+00
       784   0.988530   2.924890   0.775991 0.000000e+00
       832   0.791871   2.909214   0.769263 0.000000e+00
       880   0.941202   2.896177   0.763538 0.000000e+00
       928   1.093181   2.924231   0.768871 0.000000e+00
       976   1.291276   2.879987   0.755406 0.000000e+00
      1024   2.045877   1.049664   0.274717 0.000000e+00
      1072   0.862301   2.857297   0.746309 0.000000e+00
      1120   0.984263   2.854781   0.744282 0.000000e+00
      1168   1.126833   2.828126   0.736088 0.000000e+00
      1216   1.283442   2.801913   0.728129 0.000000e+00
      1264   1.455454   2.775063   0.720111 0.000000e+00
      1312   1.646599   2.743113   0.710868 0.000000e+00
      1360   1.860406   2.704201   0.699911 0.000000e+00
      1408   2.201576   2.535738   0.655546 0.000000e+00
      1456   2.437914   2.532187   0.653916 0.000000e+00
      1504   2.620750   2.596259   0.669780 0.000000e+00
      1552   2.846817   2.626307   0.676883 0.000000e+00
      1600   3.248074   2.522110   0.649443 0.000000e+00
      1648   3.604947   2.483149   0.638868 0.000000e+00
      1696   3.849676   2.534448   0.651544 0.000000e+00
      1744   4.256786   2.492227   0.640205 0.000000e+00
      1792   4.363923   2.637345   0.676997 0.000000e+00
      1840   4.958485   2.512664   0.644553 0.000000e+00
      1888   5.250375   2.563572   0.657187 0.000000e+00
      1936   5.557062   2.611565   0.669079 0.000000e+00
      1984   6.309863   2.475341   0.633807 0.000000e+00
Then, if we use the order p,j,i, we get the following, 
 Dimension       Time    Gflop/s       GB/s        Error
        16   0.763058   2.621035   2.621035 0.000000e+00
        64   0.771394   2.592915   1.134400 0.000000e+00
       112   0.789623   2.533635   0.904870 0.000000e+00
       160   0.767480   2.615106   0.849909 0.000000e+00
       208   0.744975   2.705805   0.832555 0.000000e+00
       256   0.779701   2.582100   0.766561 0.000000e+00
       304   0.733220   2.758794   0.798598 0.000000e+00
       352   0.720939   2.782835   0.790578 0.000000e+00
       400   0.739896   2.767955   0.775027 0.000000e+00
       448   0.814190   2.650449   0.733606 0.000000e+00
       496   0.809740   2.712513   0.743754 0.000000e+00
       544   0.899846   2.504704   0.681427 0.000000e+00
       592   0.775659   2.674817   0.722924 0.000000e+00
       640   0.824225   2.544392   0.683805 0.000000e+00
       688   1.035984   2.514793   0.672561 0.000000e+00
       736   0.883118   2.708731   0.721347 0.000000e+00
       784   1.144150   2.527066   0.670446 0.000000e+00
       832   0.912181   2.525508   0.667803 0.000000e+00
       880   1.057687   2.577216   0.679448 0.000000e+00
       928   1.181739   2.705094   0.711253 0.000000e+00
       976   1.381223   2.692438   0.706213 0.000000e+00
      1024   0.842180   2.549911   0.667359 0.000000e+00
      1072   0.922292   2.671444   0.697765 0.000000e+00
      1120   1.051573   2.672050   0.696642 0.000000e+00
      1168   1.184688   2.690015   0.700141 0.000000e+00
      1216   1.432488   2.510381   0.652369 0.000000e+00
      1264   1.569204   2.573901   0.667911 0.000000e+00
      1312   1.688123   2.675639   0.693382 0.000000e+00
      1360   1.869867   2.690519   0.696370 0.000000e+00
      1408   2.196526   2.541568   0.657053 0.000000e+00
      1456   2.338466   2.639873   0.681726 0.000000e+00
      1504   2.594295   2.622733   0.676609 0.000000e+00
      1552   3.001816   2.490698   0.641932 0.000000e+00
      1600   3.209554   2.552380   0.657238 0.000000e+00
      1648   3.439508   2.602587   0.669598 0.000000e+00
      1696   4.048282   2.410109   0.619580 0.000000e+00
      1744   4.163838   2.547860   0.654496 0.000000e+00
      1792   4.480197   2.568898   0.659427 0.000000e+00
      1840   4.828021   2.580562   0.661970 0.000000e+00
      1888   5.156652   2.610166   0.669132 0.000000e+00
      1936   5.623256   2.580823   0.661203 0.000000e+00
      1984   6.200747   2.518900   0.644960 0.000000e+00,
We can see the the original order would be the optimal. The ordering does not make 
a significant different, so I do not think the order really matters, given that we are using 
a square matrix, the loops should be symetric. 
I write a seperate version of MMult1 that implent OpenMP, namely MMult1_OpenMP.cpp. Again,
Using BlOCK_SIZE = 16, by running with OpenMP, the output is the following,
 Dimension       Time    Gflop/s       GB/s        Error
        16   1.160969   1.722701   1.722701 0.000000e+00
        64   0.262297   7.625541   3.336174 0.000000e+00
       112   0.219135   9.129592   3.260568 0.000000e+00
       160   0.159550  12.579355   4.088290 0.000000e+00
       208   0.161481  12.482946   3.840906 0.000000e+00
       256   0.131491  15.311031   4.545462 0.000000e+00
       304   0.138390  14.616630   4.231130 0.000000e+00
       352   0.142946  14.035059   3.987233 0.000000e+00
       400   0.147590  13.876245   3.885349 0.000000e+00
       448   0.142827  15.108933   4.181937 0.000000e+00
       496   0.148176  14.823126   4.064406 0.000000e+00
       544   0.154565  14.581869   3.967126 0.000000e+00
       592   0.144559  14.352226   3.878980 0.000000e+00
       640   0.136583  15.354365   4.126485 0.000000e+00
       688   0.172791  15.077643   4.032393 0.000000e+00
       736   0.161470  14.814681   3.945214 0.000000e+00
       784   0.197892  14.610671   3.876301 0.000000e+00
       832   0.150520  15.305104   4.047023 0.000000e+00
       880   0.179373  15.196792   4.006427 0.000000e+00
       928   0.216938  14.735639   3.874457 0.000000e+00
       976   0.253860  14.649240   3.842424 0.000000e+00
      1024   0.141811  15.143269   3.963277 0.000000e+00
      1072   0.161894  15.218914   3.975089 0.000000e+00
      1120   0.188016  14.944781   3.896318 0.000000e+00
      1168   0.215278  14.803298   3.852913 0.000000e+00
      1216   0.237967  15.111691   3.927051 0.000000e+00
      1264   0.269097  15.009362   3.894834 0.000000e+00
      1312   0.304750  14.821374   3.840905 0.000000e+00
      1360   0.342105  14.705757   3.806196 0.000000e+00
      1408   0.364918  15.298288   3.954955 0.000000e+00
      1456   0.439341  14.051182   3.628602 0.000000e+00
      1504   0.475349  14.313999   3.692707 0.000000e+00
      1552   0.514758  14.524519   3.743433 0.000000e+00
      1600   0.571533  14.333384   3.690846 0.000000e+00
      1648   0.665851  13.443877   3.458862 0.000000e+00
      1696   0.665182  14.667874   3.770751 0.000000e+00
      1744   0.768556  13.803651   3.545892 0.000000e+00
      1792   0.911614  12.625046   3.240804 0.000000e+00
      1840   0.853221  14.602323   3.745813 0.000000e+00
      1888   0.935041  14.394786   3.690189 0.000000e+00
      1936   0.989595  14.665214   3.757204 0.000000e+00
      1984   1.051662  14.851796   3.802779 0.000000e+00
We can see the time nearly reduce by a factor of 4, given that I am using a 4-core CPU. 


3.
After improving the accuracy to both intrin and vec, the output is the following,
Reference time: 18.1083
Taylor time:    2.4363      Error: 6.928125e-12
Intrin time:    0.7651      Error: 6.928125e-12
Vector time:    0.9485      Error: 6.928125e-12


4.  (b)
compute.cpp

First, let's run with different functions and different flags.

mult-add
03
1.672421 seconds
5.519441 cycles/eval
1.195772 Gflop/s

01
4.564908 seconds
15.064772 cycles/eval
0.438108 Gflop/s

division
03
4.394882 seconds
14.503590 cycles/eval
0.455059 Gflop/s

01
6.792349 seconds
22.415689 cycles/eval
0.294436 Gflop/s

sqrt
03
7.067186 seconds
23.322144 cycles/eval
0.282993 Gflop/s

01
9.229132 seconds
30.456703 cycles/eval
0.216701 Gflop/s

sin
03
12.416967 seconds
40.976394 cycles/eval
0.161068 Gflop/s

01
14.829930 seconds
48.939675 cycles/eval
0.134860 Gflop/s

cos
03
15.698650 seconds
51.805774 cycles/eval
0.127399 Gflop/s

01
17.867242 seconds
58.964130 cycles/eval
0.111932 Gflop/s

We can see that as our operation gets more complicated, the timings and latency also 
increase, which make sense. As opearation gets more complicated, there would be more 
evluation needed to compute the result. 

compute-vec.cpp
The following are reslut, if I run with command
g++ -fopenmp -std=c++11 -O3 -march=native compute-vec.cpp && ./a.out -n 1000000000

time = 1.507832
flop-rate = 5.305325 Gflop/s

time = 1.825898
flop-rate = 4.381328 Gflop/s

time = 1.813368
flop-rate = 4.411604 Gflop/s

Then, if I run with command 
g++ -std=c++11 -O3 -march=native compute-vec.cpp -ftree-vectorize -fopt-info-vec-optimized && ./a.out -n 1000000000

time = 1.506120
flop-rate = 5.311393 Gflop/s

time = 1.818232
flop-rate = 4.399827 Gflop/s

time = 1.815493
flop-rate = 4.406452 Gflop/s
We can see in both cases, the naive way of vectorization works the best, the intrin and vec 
gives similar result.  During the naive case, we are doing computation in a way that the complier
realized that we can vectorize each compute_fn0 as a vector operation. Because we let the 
complier realizes this by itself, no extra works needed. In the case of compute_fn1 and 
compute_fn2, we need transfer the four number into some vector structure and use the 
operation libarary there to get the reslut. So creating vectors and transfer the vector structure
back to array may cause some extra time. I think this is the reason why the navie way of doing
it gives minimum timing.

compute-vec-pipe.cpp
If we run with different M, the following are the outputs,

M=1
time = 1.812229
flop-rate = 4.413782 Gflop/s

time = 2.284858
flop-rate = 3.501193 Gflop/s

time = 1.960597
flop-rate = 4.080284 Gflop/s

--------------------------------------------------
M=4

time = 6.193900
flop-rate = 5.166236 Gflop/s

time = 2.218802
flop-rate = 14.421892 Gflop/s

time = 2.024117
flop-rate = 15.809086 Gflop/s

--------------------------------------------------
M=8

time = 11.138541
flop-rate = 5.745759 Gflop/s

time = 1.998623
flop-rate = 32.021350 Gflop/s

time = 1.895055
flop-rate = 33.771429 Gflop/s

--------------------------------------------------
M=16

time = 17.095521
flop-rate = 7.487300 Gflop/s

time = 8.323620
flop-rate = 15.377746 Gflop/s

time = 11.552689
flop-rate = 11.079595 Gflop/s

--------------------------------------------------
M = 32

time = 42.403840
flop-rate = 6.037166 Gflop/s

time = 22.259831
flop-rate = 11.500493 Gflop/s

time = 23.584275
flop-rate = 10.854669 Gflop/s

We can see that as we when we increase M to 8, we achieve the peak flop-rate in our 
experiment, and M = 32 the perforemece get worse, the processing data cannot fit into cache
anymore. We can see that when M=1, the navie way still a little bit better, as we increase the 
M, the intrin and vec, i.e. compute_fn1 and compute_fn2, have better performence. 

Here is some my thought on this, as we increase M, we allow the processor to pipeline instructions 
and use multiple execution units. However, in the navie way, given 
there is non clear vectorization structure, the complier may recognize each addition as a 
thread and try to run multiple threads on a singlue execution units. However, in other two functions
each vectorized operation is recognized as a single thread, so probably there is only one thread
per execution units, which gives the better speed. I do not this explanation is correct or not. 

Overall, when the program has enough parallelism, the intrinsic vectorization do speed things
up quite a bit. When there is not enough parallelism, the navie way of vectorization give a beeter
speeded up.